input {
     kafka {
         bootstrap_servers => "kafka:29092"
         topics => ["pm-events"]
         codec => json
         group_id => "pocmaster_logstash"
     }
}


filter {
  # Utilisation du plugin json pour analyser un champ JSON
  json {
    source => "message"
    target => "parsed_message" # Placer le contenu JSON dans un champ temporaire pour simplifier l'accès
  }

  # Processus de transformation de chaque champ de data dans PMEvent
  mutate {
    add_field => {
      "key" => "%{[parsed_message][key]}"
      "eventName" => "%{[parsed_message][eventName]}"
      "eventLocation" => "%{[parsed_message][eventLocation]}"
      "eventDescription" => "%{[parsed_message][eventDescription]}"
      "eventDate" => "%{[parsed_message][eventDate]}"
    }

    # Supprime le champ temporaire parsed_message, car les données ont été placées en top-level
    remove_field => ["parsed_message"]
  }

  # Transformation du champ de date "eventDate"
  date {
    match => ["eventDate", "ISO8601"]
    target => "eventDate"
  }
}



output {
 elasticsearch {
   index => "logstash-%{+YYYY.MM.dd}"
   hosts=> "${ELASTIC_HOSTS}"
   user=> "${ELASTIC_USER}"
   password=> "${ELASTIC_PASSWORD}"
   cacert=> "certs/ca/ca.crt"
 }
}
